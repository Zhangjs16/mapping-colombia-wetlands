{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take the training data stored in stored_training_data.p and use it to predict the specified type of wetland in each of the sub-regions. It proceeds in the following steps:\n",
    "\n",
    "    (1) get the features and labels for a given test sub-region\n",
    "    (2) assemble training data from at most r *other* sub-regions (r=5 is used here)\n",
    "    (3) use this training data to assign a wetland score between 0 and 1 to each pixel of the test sub-region\n",
    "    (4) store a raster of these predictions in the respective sub-folder\n",
    "    (5) return to (1) with the next test sub-region\n",
    "    \n",
    "Upon success, we will have predicted rasters for each of the sub-regions in stored_training_data.p; these predicted rasters will be post-processed in the next notebook: (4) PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from random import sample\n",
    "import pickle\n",
    "from common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ROI_FOLDER = 'regions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Process Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set_predictions(interior_training_vals, exterior_training_vals, split_arr_features_test, arr_test_labels, arr_test_labels_mask):\n",
    "    \"\"\"\n",
    "    This function uses the cached training data to make predictions about wetlands in a testing region\n",
    "    \n",
    "    interior_training_vals: N x k matrix of training data at pixels confidently marked as the given wetland sub-type\n",
    "    exterior_training_vals: M x k matrix of training data at pixels confidently marked as NOT the given wetland sub-type\n",
    "    split_arr_features_test: the features for the test region\n",
    "    arr_test_labels: the labels for the test region\n",
    "    arr_test_labels_mask: a data mask for the labels at the rest region\n",
    "    \"\"\"\n",
    "    \n",
    "    #get number of bands, scale, and compute how many sub-cells to sample\n",
    "    num_bands = split_arr_features_test.shape[-1]\n",
    "    scale = split_arr_features_test.shape[-2]\n",
    "    MAX_VAL = 2\n",
    "    \n",
    "    #sample from wetlands and non wetlands\n",
    "    wetland_idxs_x, wetland_idxs_y = np.where((arr_test_labels == 1)&(arr_test_labels_mask == 1))\n",
    "    \n",
    "    non_wetland_idxs_x, non_wetland_idxs_y = np.where((arr_test_labels == 0)&(arr_test_labels_mask == 1))\n",
    "    \n",
    "    #get testing indices for x and y and sample those sub-cells\n",
    "    testing_idx_wetlands = np.arange(wetland_idxs_x.shape[0])\n",
    "    wetland_idxs = (wetland_idxs_x[testing_idx_wetlands], wetland_idxs_y[testing_idx_wetlands])\n",
    "    \n",
    "    testing_idx_non_wetlands = np.arange(non_wetland_idxs_x.shape[0])\n",
    "    non_wetland_idxs = (non_wetland_idxs_x[testing_idx_non_wetlands], non_wetland_idxs_y[testing_idx_non_wetlands])\n",
    "    \n",
    "    testing_idx_tuple = (np.concatenate([wetland_idxs[0], non_wetland_idxs[0]]), np.concatenate([wetland_idxs[1], non_wetland_idxs[1]]))\n",
    "    \n",
    "    split_arr_features_test_sampled = split_arr_features_test[testing_idx_tuple]\n",
    "    arr_test_labels_sampled = arr_test_labels[testing_idx_tuple]\n",
    "    \n",
    "    #reshape the testing data into num_bands columns\n",
    "    testing_vals = split_arr_features_test_sampled.reshape(-1, num_bands)\n",
    "        \n",
    "    approx_densities_interior, histogram_wetlands = get_approx_densities(interior_training_vals, testing_vals, 2.5, 10)\n",
    "    print('got interior histogram')\n",
    "    approx_densities_exterior, histogram_non_wetlands = get_approx_densities(exterior_training_vals, testing_vals, 2.5, 10)\n",
    "    print('got exterior histogram')\n",
    "\n",
    "    scores = approx_densities_interior / approx_densities_exterior\n",
    "    scores[scores < 0] = 0\n",
    "    scores = 2/(1 + np.exp(-scores)) - 1\n",
    "\n",
    "    aux_data = {'histogram_wetlands': histogram_wetlands, 'histogram_non_wetlands': histogram_non_wetlands, 'testing_vals': testing_vals}\n",
    "        \n",
    "    scores = scores.reshape((-1,scale,scale))\n",
    "        \n",
    "    return scores, arr_test_labels_sampled, testing_idx_tuple, aux_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_map(orig_arr, scale, fill_indices, fills, post_upsample_blur=None):\n",
    "    \"\"\"\n",
    "    This function takes the predictions about a test region and generates a numpy matrix of the map so it can be\n",
    "    converted to a raster file.\n",
    "    \n",
    "    orig_arr: the original, low resultion image\n",
    "    scale: the degree of upsampling\n",
    "    fill_indices: the coordinates of orig_arr to give more continuous wetland confidence\n",
    "    fills: the continuous weland confidence scores\n",
    "    post_upsample_blur: how much to blur the resulting upsampled image to induce continuity\n",
    "    \"\"\"\n",
    "    \n",
    "    NON_SAMPLED_VALUE = -1\n",
    "    \n",
    "    #create an empty array like the original array\n",
    "    small_arr = np.ones_like(orig_arr).astype(float)*NON_SAMPLED_VALUE\n",
    "    \n",
    "    #create the eventual upsampled array\n",
    "    upsamp_arr = np.repeat(np.repeat(small_arr, scale, axis=1), scale, axis=0)\n",
    "    \n",
    "    #transform indices for the edges\n",
    "    scaled_edge_x = np.repeat(fill_indices[0]*scale, scale**2) + np.tile(np.repeat(np.arange(scale), scale), len(fill_indices[0]))\n",
    "    scaled_edge_y = np.repeat(fill_indices[1]*scale, scale**2) + np.tile(np.tile(np.arange(scale), scale), len(fill_indices[1]))\n",
    "    scaled_edges = (scaled_edge_x, scaled_edge_y)\n",
    "    \n",
    "    #vectorized setting of all continious edge wetland confidences to the appropriate portions of the upsampled array\n",
    "    upsamp_arr[scaled_edges] = fills.flatten()\n",
    "    \n",
    "    #blur the upsampled array if needed\n",
    "    if post_upsample_blur != None:\n",
    "        post_upsample_blur_kernel = np.ones((post_upsample_blur,post_upsample_blur)) / (post_upsample_blur**2)\n",
    "        convolved_arr = apply_convolution(upsamp_arr, post_upsample_blur_kernel)\n",
    "        \n",
    "        thresh = 0.2\n",
    "        upsamp_arr[convolved_arr < thresh] = 0\n",
    "    \n",
    "    return upsamp_arr, scaled_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load(open('stored_training_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_of_interest = list(training_data['training_data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wetland_type = training_data['aux_info']['wetland_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of training regions to use when predicting each testing region\n",
    "num_training_regions = min(5, len(training_data['training_data'])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_data_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regions/region_0_0_0/features_region_0_0_0.tiff regions/region_0_0_0/baseline_region_0_0_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_0_0_1/features_region_0_0_1.tiff regions/region_0_0_1/baseline_region_0_0_1.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_0_1_0/features_region_0_1_0.tiff regions/region_0_1_0/baseline_region_0_1_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_0_1_1/features_region_0_1_1.tiff regions/region_0_1_1/baseline_region_0_1_1.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_1_0_0/features_region_1_0_0.tiff regions/region_1_0_0/baseline_region_1_0_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_2_0_0/features_region_2_0_0.tiff regions/region_2_0_0/baseline_region_2_0_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_2_0_1/features_region_2_0_1.tiff regions/region_2_0_1/baseline_region_2_0_1.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_2_0_2/features_region_2_0_2.tiff regions/region_2_0_2/baseline_region_2_0_2.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_3_0_0/features_region_3_0_0.tiff regions/region_3_0_0/baseline_region_3_0_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_3_0_1/features_region_3_0_1.tiff regions/region_3_0_1/baseline_region_3_0_1.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_3_1_0/features_region_3_1_0.tiff regions/region_3_1_0/baseline_region_3_1_0.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n",
      "regions/region_3_1_1/features_region_3_1_1.tiff regions/region_3_1_1/baseline_region_3_1_1.tiff\n",
      "Getting formatted features and labels...\n",
      "Assembling training data...\n",
      "Building Histograms...\n",
      "got interior histogram\n",
      "got exterior histogram\n",
      "Generating Predicted Map...\n",
      "Saving Predicted Map to Raster...\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "for folder in regions_of_interest:\n",
    "        \n",
    "    test_labels_file = '%s/%s/baseline_%s.tiff'%(BASE_ROI_FOLDER, folder, folder)\n",
    "    test_features_file = '%s/%s/features_%s.tiff'%(BASE_ROI_FOLDER, folder, folder)\n",
    "    \n",
    "    print(test_features_file, test_labels_file)\n",
    "    \n",
    "    ds_features = gdal.Open(test_features_file, gdal.GA_ReadOnly)\n",
    "    ds_labels = gdal.Open(test_labels_file, gdal.GA_ReadOnly)\n",
    "    gt_labels = ds_labels.GetGeoTransform()\n",
    "\n",
    "    #get other regions that will be used for training\n",
    "    other_regions = sample([item for item in training_data['training_data'].keys() if item != folder], num_training_regions)\n",
    "\n",
    "    print('Getting formatted features and labels...')\n",
    "    arr_test_labels, split_arr_features_test, gt_features_test = preprocess_data_set_pair(ds_features, ds_labels, wetland_type)\n",
    "\n",
    "    print('Assembling training data...')\n",
    "    interior_training_vals = np.concatenate([training_data['training_data'][oth]['interior'] for oth in other_regions], axis=0)\n",
    "    exterior_training_vals = np.concatenate([training_data['training_data'][oth]['exterior'] for oth in other_regions], axis=0)\n",
    "\n",
    "    #build mask for test region labels\n",
    "    arr_test_labels_mask = np.ones_like(arr_test_labels)\n",
    "    arr_test_labels_mask[(split_arr_features_test == NO_DATA_VALUE).any(axis = (2,3,4))] = 0\n",
    "    arr_test_labels_mask[arr_test_labels ==-1] = 0\n",
    "\n",
    "    print('Building Histograms...')\n",
    "    scores, arr_test_labels_sampled, testing_idx_tuple, aux_data = get_test_set_predictions(interior_training_vals, exterior_training_vals, split_arr_features_test, arr_test_labels, arr_test_labels_mask)\n",
    "    aux_data_dict[folder] = aux_data\n",
    "    \n",
    "    scale = split_arr_features_test.shape[-2]\n",
    "\n",
    "    print('Generating Predicted Map...')\n",
    "    filled_arr, scaled_edges = predictions_to_map(arr_test_labels, scale, testing_idx_tuple, scores)\n",
    "\n",
    "    fname_predicted = '%s/%s/predicted_%s.tiff'%(BASE_ROI_FOLDER, folder, folder)\n",
    "    fname_specific_baseline = '%s/%s/baseline_%s_%s.tiff'%(BASE_ROI_FOLDER, folder, wetland_type.replace('/','').replace(' ',''), folder)\n",
    "\n",
    "    print(\"Saving Predicted Map to Raster...\")\n",
    "    ds = np_array_to_raster(fname_predicted, filled_arr, gt_features_test, no_data=-1, nband=1, gdal_data_type=gdal.GDT_Float64)\n",
    "    ds = None\n",
    "    \n",
    "    ds = np_array_to_raster(fname_specific_baseline, arr_test_labels, gt_labels, no_data=-1, nband=1, gdal_data_type=gdal.GDT_Float64)\n",
    "    ds = None\n",
    "    \n",
    "    ds_features = None\n",
    "    ds_labels = None\n",
    "\n",
    "    print('===============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
