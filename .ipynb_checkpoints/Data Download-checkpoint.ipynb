{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/ritvik/Desktop/JPLProject/mapping-colombia-wetlands/')\n",
    "\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is about 10 meters\n",
    "METERS_TO_DECIMAL_DEGREES_CONST = 1/30/3600\n",
    "\n",
    "#the value we use to signify no data at a pixel\n",
    "NO_DATA_VALUE = 65535\n",
    "\n",
    "#this is the biggest region we allow to avoid data overflow errors and keep files manageable\n",
    "MAX_REGION_SIZE = 0.5\n",
    "\n",
    "#this is the baseline wetland path\n",
    "BASELINE_WETLAND_PATH = 'C://Users/ritvik/Desktop/JPLProject/data/CIFORWetlands/cifor_wetlands_colombia.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_raster_by_shapefile(source_raster, shapefile_path, save_path):\n",
    "    \"\"\"\n",
    "    Given some raster, this function clips the raster gien the shape of another raster\n",
    "    \"\"\"\n",
    "    source_ds = gdal.Open(source_raster, gdal.GA_ReadOnly)\n",
    "    \n",
    "    options = gdal.WarpOptions(format='GTiff', cutlineDSName=shapefile_path, cropToCutline=True)\n",
    "    ds = gdal.Warp(save_path, source_ds, options=options)\n",
    "    \n",
    "    ds = None\n",
    "    source_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_region_folders(minx, miny, maxx, maxy, path):\n",
    "    \"\"\"\n",
    "    Using the given extent, create a folder with shapefile info at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    diff_x = (maxx - minx)\n",
    "    diff_y = (maxy - miny)\n",
    "    \n",
    "    num_x = int(diff_x // MAX_REGION_SIZE + 1)\n",
    "    num_y = int(diff_y // MAX_REGION_SIZE + 1)\n",
    "    \n",
    "    size_x = diff_x / num_x\n",
    "    size_y = diff_y / num_y\n",
    "    \n",
    "    print(num_x, num_y, size_x, size_y)\n",
    "    \n",
    "    for i in range(num_x):\n",
    "        for j in range(num_y):\n",
    "            geo_box = box(minx+i*size_x, miny+j*size_y, minx+(i+1)*size_x, miny+(j+1)*size_y)\n",
    "            df = gpd.GeoDataFrame(geometry=[geo_box], crs={'init':'epsg:4326'})\n",
    "            df.to_file('%s_%s_%s'%(path, i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands_from_region(folders_to_process, features, gdrive_folder, date_range, aux_data, primary_dataset):\n",
    "    \"\"\"\n",
    "    folders_to_process: the folders where to find the regions of interest\n",
    "    features: a dictionary of features to include in the resulting data cubes\n",
    "    gdrive_folder: the name of the folder on Google Drive to store the results\n",
    "    date_range: the date range for this data\n",
    "    aux_data: dictionary of source-specific info such as cloudy pixel percentage for Sentinel, etc.\n",
    "    primary_dataset: the dataset to use for the eventual image resolution\n",
    "    \"\"\"\n",
    "    \n",
    "    #this will store all started tasks\n",
    "    tasks = {}\n",
    "    \n",
    "    for region_folder in folders_to_process:\n",
    "        \n",
    "        filtered_imgs = []\n",
    "        region_name = region_folder.split('/')[-1]\n",
    "        \n",
    "        print('Working on region folder: %s...'%region_name)\n",
    "        \n",
    "        print('Created Baseline Wetlands Raster...')\n",
    "        clip_raster_by_shapefile(BASELINE_WETLAND_PATH, '%s/%s.shp'%(region_folder, region_name), '%s/baseline_%s.tiff'%(region_folder, region_name))\n",
    "    \n",
    "        #read the area of interest\n",
    "        df = gpd.read_file(region_folder)\n",
    "\n",
    "        #get the coordinates of that area\n",
    "        area_coords = df.geometry[0].exterior.coords[:]\n",
    "        area_coords = [list(pair) for pair in area_coords]\n",
    "\n",
    "        #get the minx, miny, maxx, maxy\n",
    "        x1 = min([item[0] for item in area_coords])\n",
    "        y1 = max([item[1] for item in area_coords])\n",
    "\n",
    "        x2 = max([item[0] for item in area_coords])\n",
    "        y2 = min([item[1] for item in area_coords])\n",
    "\n",
    "        #store the reference coordinates\n",
    "        ref_coords = (x1,y1)\n",
    "\n",
    "        #create an area of interest from Earth Engine Geometry\n",
    "        area_of_interest = ee.Geometry.Polygon(coords=area_coords)\n",
    "\n",
    "        #iterate over each data source\n",
    "        for data_source, band_combos in features.items():\n",
    "                \n",
    "            print('Working on data source: %s...'%data_source)\n",
    "            \n",
    "            for band_names in band_combos:\n",
    "\n",
    "                #access the Earth Engine image collection with the specified bands\n",
    "                data = ee.ImageCollection(data_source).select(band_names)\n",
    "\n",
    "                #filter on date range\n",
    "                data_filtered = data.filterBounds(area_of_interest).filterDate(date_range[0], date_range[1])\n",
    "\n",
    "                #filter on auxilary data\n",
    "                for title, info in aux_data:\n",
    "                    data_filtered = data_filtered.filterMetadata(title, info['relation'], info['value'])\n",
    "\n",
    "                #ensure there is at least 1 image\n",
    "                num_items = data_filtered.size().getInfo()\n",
    "                if num_items == 0:\n",
    "                    print('no items found, returning started tasks.')\n",
    "                    return tasks\n",
    "\n",
    "                band_info = data_filtered.first().getInfo()['bands'][0]\n",
    "\n",
    "                #if crs is already EPSG 4326, get resolution directly, otherwise need to transform from meters\n",
    "                if band_info['crs'] == 'EPSG:4326':\n",
    "                    res = band_info['crs_transform'][0]\n",
    "                else:\n",
    "                    res = band_info['crs_transform'][0] * METERS_TO_DECIMAL_DEGREES_CONST\n",
    "                    \n",
    "                if data_source == primary_dataset:\n",
    "                    eventual_res = res\n",
    "\n",
    "                #get a mosaic\n",
    "                mosaic = ee.Image(data_filtered.median())\n",
    "                \n",
    "                filtered_imgs.append(mosaic)\n",
    "                \n",
    "        fname = '%s_%s'%(region_folder.split('/')[-1], '_'.join(list(features.keys())).replace('/','_'))\n",
    "        print(fname)\n",
    "        \n",
    "        #add the various layers on top of each other to create a data cube with all features\n",
    "        final_img = ee.Image()\n",
    "        for img in filtered_imgs:\n",
    "            final_img = ee.Image.addBands(final_img,img)\n",
    "        \n",
    "        #use the qa band to filter out invalid pixels\n",
    "        qa_band = final_img.select('qa')\n",
    "        qa_mask = qa_band.lt(51)\n",
    "        \n",
    "        #use the SCL band to filter out invalid pixels\n",
    "        scl_band = final_img.select('SCL')\n",
    "        scl_nodata_vals = [0,3,6,8,9,10]\n",
    "        scl_mask = scl_band.eq(0)\n",
    "        for v in scl_nodata_vals:\n",
    "            scl_mask = scl_mask.Or(scl_band.eq(v))\n",
    "         \n",
    "        #store the result with just the needed bands\n",
    "        result = final_img.where(qa_mask.Or(scl_mask), NO_DATA_VALUE)\n",
    "        result = result.select('B2', 'B3', 'B4', 'B8', 'HH', 'HV')\n",
    "        \n",
    "            \n",
    "        #define the task to gather the data\n",
    "        task = ee.batch.Export.image.toDrive(image=result,\n",
    "                                             region=area_of_interest.getInfo()['coordinates'],\n",
    "                                             description=region_folder.split('/')[-1],\n",
    "                                             folder=gdrive_folder,\n",
    "                                             fileNamePrefix=fname,\n",
    "                                             crs_transform=[eventual_res, 0.0, ref_coords[0], 0.0, -eventual_res, ref_coords[1]],\n",
    "                                             crs='EPSG:4326')\n",
    "        \n",
    "        #start up the task\n",
    "        task.start()\n",
    "        \n",
    "        tasks[fname] = task\n",
    "    \n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=== SET YOUR AREA OF INTEREST HERE ===\n",
    "PARAMETERS ARE: (minx, miny, maxx, maxy, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 0.4902000000000015 0.45260000000000006\n"
     ]
    }
   ],
   "source": [
    "generate_region_folders(-73.427, 2.65, -70.976, 4.913, 'C://Users/ritvik/Desktop/JPLProject/data/GoogleEarthEngineData/Sentinel2/roi/inland_wetland')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=== SET YOUR PARAMETERS HERE ===\n",
    "regions_folder: path where all your individual sub-regions are\n",
    "search_area_name: the prefix of the folders you would like to process\n",
    "features: which features to use in the wetland prediction\n",
    "date_range: the date range to get data from Google Earth Engine\n",
    "gdrive_folder: the name of the folder on Google Drive where your data will go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_folder = 'C://Users/ritvik/Desktop/JPLProject/data/GoogleEarthEngineData/Sentinel2/roi/'\n",
    "search_area_name = 'inland_wetland_0'\n",
    "folders_to_process = [regions_folder+item for item in os.listdir(regions_folder) if search_area_name in item]\n",
    "features = {'JAXA/ALOS/PALSAR/YEARLY/SAR': [['HH', 'HV', 'qa']], 'COPERNICUS/S2_SR': [['B2', 'B3', 'B4', 'B8', 'SCL']]}\n",
    "date_range = ['2017-01-01', '2019-01-01']\n",
    "gdrive_folder = 'GoogleEarthEngine'\n",
    "aux_data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on region folder: inland_wetland_0_0...\n",
      "Created Baseline Wetlands Raster...\n",
      "Working on data source: JAXA/ALOS/PALSAR/YEARLY/SAR...\n",
      "Working on data source: COPERNICUS/S2_SR...\n",
      "inland_wetland_0_0_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR\n",
      "Working on region folder: inland_wetland_0_1...\n",
      "Created Baseline Wetlands Raster...\n",
      "Working on data source: JAXA/ALOS/PALSAR/YEARLY/SAR...\n",
      "Working on data source: COPERNICUS/S2_SR...\n",
      "inland_wetland_0_1_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR\n",
      "Working on region folder: inland_wetland_0_2...\n",
      "Created Baseline Wetlands Raster...\n",
      "Working on data source: JAXA/ALOS/PALSAR/YEARLY/SAR...\n",
      "Working on data source: COPERNICUS/S2_SR...\n",
      "inland_wetland_0_2_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR\n",
      "Working on region folder: inland_wetland_0_3...\n",
      "Created Baseline Wetlands Raster...\n",
      "Working on data source: JAXA/ALOS/PALSAR/YEARLY/SAR...\n",
      "Working on data source: COPERNICUS/S2_SR...\n",
      "inland_wetland_0_3_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR\n",
      "Working on region folder: inland_wetland_0_4...\n",
      "Created Baseline Wetlands Raster...\n",
      "Working on data source: JAXA/ALOS/PALSAR/YEARLY/SAR...\n",
      "Working on data source: COPERNICUS/S2_SR...\n",
      "inland_wetland_0_4_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR\n"
     ]
    }
   ],
   "source": [
    "tasks = get_bands_from_region(folders_to_process, features, gdrive_folder, date_range, aux_data, 'COPERNICUS/S2_SR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inland_wetland_0_0_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR COMPLETED\n",
      "inland_wetland_0_1_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR COMPLETED\n",
      "inland_wetland_0_2_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR RUNNING\n",
      "inland_wetland_0_3_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR COMPLETED\n",
      "inland_wetland_0_4_JAXA_ALOS_PALSAR_YEARLY_SAR_COPERNICUS_S2_SR COMPLETED\n"
     ]
    }
   ],
   "source": [
    "for name,task in tasks.items():\n",
    "    print(name, task.status()['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
